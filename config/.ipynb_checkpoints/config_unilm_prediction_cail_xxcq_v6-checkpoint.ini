[paths]

config_path = albert_data/bert_config_ilm_large.json
vocab_path = albert_data/vocab_ch.txt
schema_data = duie_cail22_xxcq:albert_data/schema.json
model_type = roberta

# Micro_F1: 90.06085, Micro_Recall: 91.23288, Micro_Precision: 88.91856
output_path = albert_data/unilm_roberta_large_with_nce_ilm_mixture_final_nce_v6_nomix_add_entity/


[para]
maxlen = 256
batch_size = 4
epochs = 10
head_size = 128
lr = 1e-5
fp_16 = True
